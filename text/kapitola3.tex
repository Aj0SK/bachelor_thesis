\chapter{Towards Building a Squiggle Index}

\label{kap:methAdjust}

In this chapter, we use the results and findings from the previous chapter. We will
use our discretization algorithm to build the index data structure that can
find the query squiggle in the simulated reference squiggle.

\section{Index idea}
\label{section:indexIdea}

As we mentioned in Section \ref{section:selectiveSequencing}, before selective sequencing
we are usually only provided the reference DNA sequence.
When we obtain the reference DNA sequence, we transform it to signal using our simulation
process from Section \ref{section:simulateSquiggle}. We choose the number of the windows - $w$ -
as a parameter for our discretization algorithm and create the reference level string.
Then, when the real signal from the squiggle arrives, we will perform the same process
that we performed with the simulated reference signal. Now, we have one reference level string and
one query level string which we want to find in it. Note that this can be better formulated as an
algorithmic problem. However, as we see in the Section \ref{section:results}, there is a minimal probability that the level string
of the longer squiggle will match perfectly to some area in the reference level string.
Instead of looking for the exact match in the reference, we will cut the reference
level string into overlapping subsequences of length $k$ and put them into a hash table.
Hash table is a data structure that allows insertion and search of an element in
amortized time complexity $O(1)$. When we have this hash table ready after the
preprocessing, we can start with the actual squiggle processing. For every squiggle, we will
build the level string. Then, we will cut it into the overlapping
subsequences of the same length $k$ and see how many of them can be found in our
prepared hash table. We call all the subsequences of length $k$ from our query squiggle that are
present in the prepared hash table \textit{hits}. Our initial assumption is that the number
of hits will be considerably higher for the squiggle that belongs to the reference.

The important thing is that we need to only use the shortest possible part of the squiggle
and also use only the readouts from the beginning of the squiggle.

\section{Building the Index}

We now choose one \textit{contig} from the reference sequence. The contig is a
standalone DNA sequence, most of the time representing the single chromosome
of the organism. It is smaller than the whole reference which consists of multiple contigs.
We will build the index over the simulated signal from this reference. We will predict,
based on the number of hits that squiggle shares with our reference, if the read is from the reference contig
or not. We will build the index in the slightly different way than we described in \ref{section:indexIdea}.
At first, we will simulate the signal from the whole contig creating one, very long simulated contig squiggle.
Then we use the sliding window of size $5\,000$ with the window step equal to $3\,000$.
For every of this small windows, we will normalize the signal that is contained in it, smooth
it using the techniques we described and then create the level string from this signal.
We will cut this smaller level string into overlapping $k$-mers that we insert into the
hash table. We will be working with the $2\,000$ readouts from the query squiggles. If this
query squiggle matches somewhere simulated signal, it will be covered by one of our windows.

As a reference contig we will take one of the contigs of the \textit{sapIng} reference.
Besides this, we will have two sets of reads, one containing reads from the \textit{sapIng}
dataset and the other one containing reads from the \textit{sapFun} dataset. Both of these datasets
are described in Section \ref{section:data}. We call the reads from the first set the
positive reads and the other negative reads. We use 190 reads from the both datasets.
We are interested in finding if our index can work as a good predictor. It will be
deciding if the squiggle is from the reference based only on the number of hits.
Figure \ref{obr:roc_index} shows what is the ROC curve of our index as a classificator.

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.3\textheight]{images/roc_index}}
\caption[TODO]{ROC curve describing how good predictor is our index. Its decisions
are based on the number of hits of the respective squiggle}
\label{obr:roc_index}
\end{figure}

We see that our index is not performing good. After looking at our index, we can
see that some of the $k$-mers have very big number of occurences in the indexed
reference level string. We suspect that these $k$-mers are not that informative
because they are very common and they carry more information about the specific
properties of the level string rather than information about the underlying signal.
Figure \ref{obr:kmerCoverage} shows what part of the reference is covered by the $k$-mers
up to a certain frequency. We can see that a lot of $k$-mers are in our reference
level string more than $2\,000$ times.

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.3\textheight]{images/kmerCoverage}}
\caption[TODO]{On $y$ axis is the percentage of the reference covered by the $k$-mers up to specific frequency
denoted on the $x$-axis.}
\label{obr:kmerCoverage}
\end{figure}

TODO: Graf pre rozne cut-offy.

\section{Aligning the squiggle level string}
\label{section:alignMinimap}

After failing to tackle this way harder problem, we will look at an easier task. We would want to see how
our discretization suits this usage and how similar is level string of the whole squiggle
comparing it to the reference level string. For this purpose, we will try to
find our query level string in the reference level string.

We already know that it does not make sense to look for the exact match of the query string in the reference
so we will need some string searching technique that can deal with few errors.
Our alignment algorithm presented in Section \ref{section:alignment} could be adapted but it lacks the neccessary speed. This
algorithm works in the time complexity $O(r\cdot s)$ where $r$ is the length of the
reference sequence and $q$ is the length of the query string. Many algorithms are able
to do this fast and with very high accuracy. We decided to tweak a Minimap2 \cite{li2018minimap2} algorithm. This is
one of the most popular DNA sequence aligning algorithms. This algorithm can take the
query DNA sequence and find it in a long reference DNA sequence. It is also able to
find the query DNA string even if it does not exactly match any subsequence precisely.
Hovewer, this algorithm works only with the DNA sequences. What we will do is that we choose
the number of levels $w=4$. This will cause that the reference and query level strings will both consist of
the characters 'a', 'b', 'c', 'd'. We then substitute 'a', 'b', 'c', 'd' by
'A', 'C', 'G', 'T' subsequently. We now obtained the manipulated level strings that
are represented using the DNA sequences. Now, we can use the Minimap2 algorithm for
finding our manipulated query level string in the manipulated reference level string.
As the Minimap2 is most of the time used and also optimized to perform well on DNA
sequences, we need to be careful of some catches that come with using it for this
purpose. For example, we need to ignore the hits on the reverse strand as the
reverse strand does not carry the same information as in the real DNA sequence.
This also speeds up the whole algorithm considerably.

We now take the level string of the relatively big part of the squiggle. We take the
fixed part of the squiggle from the $5\,000$th readout to the $60\,000$th. Of the 50
tested squiggles, all of them were correctly aligned to the correct contig and also
correct position. This was a very promising result, so we decided to optimize a
Minimap2 algorithm with adjusting some hyperparameters that this algorithm allows us
to change to speed it up. For this solution, to be usable, we need to take only
a shorter part of squiggle and from the start of it. With signal from the $5\,000$th
readout to the $10\,000$th we have been able to find only the 31 out of 100 squiggles
in around 1 minute.

\section{Alignment Algorithms Inspiration}

The second approach that we tried is similar to how the alignment algorithms like
Minimap2 work. The first approach of these algorithms is to find the pairs of the shorter
exactly matching sequences. These are then used as the kernels of the alignment. We want
to use kernels as the starting points, to see where are the places that could lead to the
successful matching of the query level strings.

In order to try this approach we need to know what is the ideal length of this short
sequence. We need to find the maximum length of the $k$ for the particular level
such that level string from most of the squiggles will have at least one $k$-mer
of this length common with their corresponding simulated reference level string.
So we run the experiment on the data used in the previous experiments in Section
\ref{section:results}. Now, instead of working with the signal of the length
$5\,000$ we will work with the smaller number of $2\,000$ readouts so we
simulate the conditions during the real DNA sequencing. In the table \ref{tab:sharedKmers}
we can see the number of the squiggles with at least one shared $k$-mer with their reference
level string. We bring the values for the multiple levels. Based on this table,
we can expect what length of $k$-mer for the particular number of levels will be located
in the reference at least one time. We want to find the good tradeof between number of
squiggles that we will be able to find and the length of the $k$-mer which determines
the number of hits in the index we have to investigate.

\begin{table}
% v tabulke sa popis zvykne davat nad tabulku
\caption[TODO]{The number of squiggles with the at least 1 one shared $k$-mer with their
reference for particular number of levels}
%id tabulky
\label{tab:sharedKmers}
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|}
\hline
level number & \multicolumn{10}{|c|}{$k$-mer lengths} \\
\hline
4 & 16 & 17 & 18 & 19 & 20 & 21 & 22 & 23 & 24 & 25 \\\cline{2-11}
& 200 & 199 & 198 & 196 & 195 & 186 & 180 & 174 & 163 & 148 \\\cline{2-11}
\hline
5 & 17 & 18 & 19 & 20 & 21 & 22 & 23 & 24 & 25 & 26 \\\cline{2-11}
& 200 & 199 & 199 & 197 & 190 & 184 & 176 & 163 & 158 & 148 \\\cline{2-11}
\hline
7 & 15 & 16 & 17 & 18 & 19 & 20 & 21 & 22 & 23 & 24 \\\cline{2-11}
& 200 & 199 & 198 & 195 & 183 & 167 & 157 & 132 & 119 & 100 \\\cline{2-11}
\hline
9 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & 21 & 22 \\\cline{2-11}
& 200 & 199 & 191 & 184 & 160 & 134 & 108 & 86 & 71 & 49 \\\cline{2-11}
\hline
11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & 21 \\\cline{2-11}
& 200 & 199 & 192 & 175 & 153 & 124 & 95 & 72 & 54 & 41 \\\cline{2-11}
\hline
13 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 \\\cline{2-11}
& 200 & 196 & 190 & 176 & 152 & 122 & 82 & 63 & 44 & 28 \\\cline{2-11}
\hline
\end{tabular}
\end{center}
\end{table}

Now, when we have for all the levels the particular number of $k$ that
has the minimal number of hits for most of the reads we can proceed to use
this information. We will focus on the pairs of the level-$k$-mer length
where the number of squiggles with at least one read is around $175$.
We now take the entire reference of the sapIng dataset and $200$ reads from this
reference. We will want to know, what is the mean and median number of hits of
these squiggles in the entire reference and what is the number of the hits between
the squiggle and its simulated counterpart. We need to push the number of $k$-mers
for the particular number of levels as high as possible such that the large percentage
of reads still share at least some $k$-mers with their simulated squiggle but the
overal number of hits in the whole reference is smallest possible. What happens
if we do not push the $k$-mer length enough is that we receive a lot of false hits in
the entire reference. If we push too much, we will lose even the good hits and the
results will be some random hits in the entire reference that represent very similar
signal but not our target signal.

\begin{table}
\caption[TODO]{The number of hits in the whole reference vs hits in the simulated
squiggle corresponding to the real squiggle}
%id tabulky
\label{tab:hitsRefvsSimul}
\begin{center}
\begin{tabular}{|l|l|c|c|c|c|}
\hline
levels & $k$-mer & \specialcell{mean hits\\in ref} & \specialcell{median hits\\in ref} & \specialcell{mean hits\\in simulated} & \specialcell{median hits\\in simulated} \\
\hline
4 & 22 & 223446.62 & 193751.0 & 16.28 & 12.0 \\
\hline
4 & 23 & 153540.78 & 132338.0 & 13.1 & 8.0 \\
\hline
5 & 21 & 401133.12 & 363887.5 & 23.32 & 19.5 \\
\hline
5 & 22 & 275380.16 & 241922.5 & 18.26 & 14.5 \\
\hline
5 & 23 & 192186.58 & 158792.5 & 14.54 & 9.0 \\
\hline
7 & 20 & 271556.42 & 265182.0 & 17.06 & 14.5 \\
\hline
7 & 21 & 175926.02 & 169163.0 & 12.88 & 10.5 \\
\hline
9 & 18 & 213360.74 & 191186.0 & 12.54 & 10.5 \\
\hline
9 & 19 & 127401.82 & 107961.5 & 8.58 & 7.0 \\
\hline
9 & 20 & 76321.34 & 58724.0 & 5.96 & 5.0 \\
\hline
11 & 16 & 243431.82 & 231441.5 & 11.16 & 8.5 \\
\hline
11 & 17 & 132439.22 & 126377.0 & 6.56 & 4.0 \\
\hline
11 & 18 & 72565.3 & 63293.0 & 3.78 & 2.0 \\
\hline
13 & 14 & 371994.38 & 326821.0 & 16.14 & 14.0 \\
\hline
13 & 15 & 194185.4 & 157827.5 & 10.18 & 8.0 \\
\hline
\end{tabular}
\end{center}
\end{table}

Now we see that the number of hits in the whole reference is really high. We can introduce smaller hashtables
or sets, just like in the first experiment. This can help us unfilter bad hits as the number
