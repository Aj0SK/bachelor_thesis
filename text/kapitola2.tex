\chapter{Squiggle Discretization and Similarity Between Squiggles}

\label{kap:proposedMethod}

As we stated in the previous chapter, we will work directly with the squiggles instead
of the basecalled sequences. However, for this to be possible we need to simulate
the reference squiggle from the reference DNA sequence and also represent the signal
in different way so that signal can be easily searchable. This will allows us to create
a special index over the simulated reference squiggle that we can then use for fast searching
during the selective sequencing.

\section{Squiggles as Sequences of Discrete Observations}

Given a simulated squiggle from the reference DNA, we want to decide whether the
squiggle passing through the pore has originated from the reference. This task
can be reformulated as finding if the current squiggle is similar to a segment of the reference squiggle.

We propose to discretize the squiggles to facilitate their better representation
and also provide easy searching capabilities in this representation. Note that, we are
not very limited by the preprocessing time, but very fast processing is required during
the sequencing of DNA. This puts certain speed limitations on our discretizing
process during the actual sequencing of the DNA.

We will represent the squiggle as a string of characters. We split the squiggle
vertically into several windows so that everything between the minimum and maximum
value is allocated to one of these windows. The windows are of a constant width and do not
overlap. More formally, let $a_i$ be the readout at the time $i$ and $m$ be the number of
vertical windows. Denote the squiggle $s$ of length $n$ as $s=a_1a_2a_3\cdots a_n$.
Besides this, we are given values $min_a$, $max_a$ that $\forall a_i: min_a \leq a_i < max_a$.
We say that the readout $a_i$ is in $j$-th window if it holds that:

\begin{center}
$min_a + j\cdot \frac{max_a-min_a}{m} \leq a_i < min_a + (j+1)\cdot \frac{max_a-min_a}{m}$
\end{center}

Let the readouts $a_0, a_1, \cdots, a_n$ correspond to the windows $w_0, w_1, \cdots ,w_n$
respectively. $ls$ such that $ls=w_1w_2\cdots w_n$ is called \textit{level sequence}.
Level sequence in which the subsequent appearances of the same character are substituted
by the single apperance of that character is called the \textit{level string} of the squiggle $s$.
We will call the transformation from the level sequence to the level string a \textit{contraction}.
So if the $ls=aabccaa$ then the level string from this level sequence is "abca". An example of the transformation
of the squiggle to the level string for $w=6$ is shown in Figure \ref{obr:levelsCreation}.

\begin{figure}
\centerline{\includegraphics[width=0.8\textwidth, height=0.4\textheight]{images/levelsCreation}}
\caption[TODO]{Squiggle with the level string displayed on the x-axis}
\label{obr:levelsCreation}
\end{figure}

Discretization has several important properties that we will use later.
First, it is deterministic and the same squiggle has the same level
string each time for the unchanged $w$. Second, small changes and variance in the signal readouts
are unlikely to change the resulting level string most of the time. Note that the squiggle
consists of some events that are represented by a longer signal that is around the same level.
With this method, we hope that each event will remain insde a single window. Subsequent
contraction of the level string thus results in one event being represented by
a signle character of a level string in most cases.

Changes of the parameter $w$ balance specificity and informativness of our method.
With the $w=2$ we can not say a lot about two squiggles that have the same level string.
With larger $w$ we can miss two squiggles from the same DNA sequence if there is
a too much noise present in one of them.

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.3\textheight]{images/levelDiff}}
\caption[TODO]{Examples of the squiggle divided into 3 and 12 windows}
\label{obr:levelDiff}
\end{figure}

Consider two scenarios when the number of levels is small and high.
Figure \ref{obr:levelDiff} shows that for the small number of levels, a lot of
different events stay in the same center window even if the higher number of levels
could distinguish between these individual events. With a high number of levels,
like we see in Figure \ref{obr:levelDiff} one event is less likely to remain within the same window.
We will address the signal oscillations in more detail in Section \ref{subsection:oscillations}.

\section{Simulating Squiggles from the Reference}

We stated that we need to obtain reference squiggle that we can sample and use
later to split squiggles between that we are interested in and not interested in.

We are given the reference in the form of a DNA sequence and our goal is to create
the reference squiggle. We create a simulated squiggle based on the 6-mer model,
where each subsequent 6-mer in our reference DNA will generate a signal (event) equal to
the mean of the gaussian distribution for that particular 6-mer. This mean value
is the information provided for us by the manufacturer of MinION through the kmer model
that we already mentioned in Section \ref{section:dnaSequencing}.

Our simplistic approach to signal simulation does not take into account that the
signal from one nucleotide is measured several times. Thus, we replicate every entry in the simulated signal
10 times.

We now compare the simulated squiggle to some real squiggle that arose from the real
sequencing. Moreover, we do not want to compare our simulated squiggle with some unrelated squiggle
but with the squiggle that corresponds to the same DNA region. Most of the time we
compare the real signal and simulated signal such that we take some real squiggle.
Then we find the part of the DNA reference that this squiggle corresponds to only
after successfully finding this part of the DNA reference we simulate
the squiggle from it. There are two
ways how we do this in our work. The first, more accurate method is to
use Nadavca. This tool, already introduced in Section \ref{section:currState} takes
as the input the reference DNA sequence and the particular squiggle we want to find in
in it. It then returns the table that accurately maps the nucleotides to the individual
events in the squiggle. This possibility is very accurate and gives a lot of information
that we do not need most of the time such as the mapping between the nucleotides
and events. We are interested only in location of the start and end of the squiggle
in the reference. The second option is to take the read.
Hovewer, we know that the DNA sequence in read is generated by the basecaller algorithm so it has some error
in it. To obtain the sequence of the nucletides corresponding to this read without
errors, we need to use some algorithm that is able to find this erroneous DNA
sequence in the reference DNA sequence. For this purpose, we use minimap2 algorithm
that we describe more closely in the Section \ref{section:alignMinimap}. This is way faster
process as the solution using Nadavca and we will use this option anytime when we need
speed and do not need any additional information that Nadavca provides.

Figure \ref{obr:simVsReal} compares the simulated squiggle to the squiggle obtained
by sequencing the same region of the DNA. Both signals were normalized by subtracting
mean and dividing by standard deviation to put them on the same scale.

\begin{figure}
\centerline{\includegraphics[width=0.7\textwidth, height=0.3\textheight]{images/simulateRef}}
\caption[TODO]{Simulated signal vs real signal, normalized}
\label{obr:simVsReal}
\end{figure}

Now we have a simulated reference squiggle. We can see on \ref{obr:simVsReal} that the simulated and real
squiggle are not identical. This poses a problem as we want to have these squiggles as
similar as possible. The first thing that we want to consider is normalization.
One of the most wide-spread ways of doing this is to subtract mean and dividing
squiggle by the standard deviation. The other possible solution is subtracting median value
as the frequent outliers can deform the mean. We will stick to the first solution
but we will remove outliers in a way that everything over and under some value will
be clamped to the target range. Most of the time this will be -2 for the lower bound
and 2 for the upper bound.

Another visible problem can be seen when we compare events in the simulated and real squiggle.
The events in the simulated signal are perfectly straight. In the real signal, we can sometimes see
the phenomenon called \textit{drift}. This is a fact that real event tends to slide
up or down over time. Another difference is that real squiggle
is sometimes contracted in some places. This is caused by the fact that the DNA
molecule is not moving through the pore at a constant speed.

There are two possible ways how to overcome the differences between real squiggle
and simulated squiggle. One approach is to make the simulated squiggle more like
the real squiggle, including adding a noise and a varying event deviation. In fact there
are more advanced squiggle simulators such as DeepSimulator\cite{deepsimulator}.

The opposite approach is to make the real squiggle less noisy. We decided to go the
second way so we will now address the most important differences between the
real and simulated squiggles.

\subsection{Signal oscillations and continuity}
\label{subsection:oscillations}

We already saw in Fig. \ref{obr:simVsReal} that one of the biggest differences between simulated and
real squiggle is the noise which can be seen as small oscillations of the signal. This is
one of the reasons that we use windows - so small oscillations within the window
are dealt with. We can also pretty easily adapt the number of windows.
However, when our method is used without any modifications it
produces much longer level string for real squiggles than for simulated squiggles.
The problem arises when the oscillations are located on the borders of the windows.
This is something that unfortunately happens too often. There are several
possibilities to deal with this behavior not affecting speed too
much. We tried several smoothing techniques to reduce noise. \textit{Moving average} is the
smoothing technique that for every entry $s_i$ in some signal $s$ count its new value
$snew_i$ as $snew_i = avg(s_{i}, s_{i-1}, s_{i-2}, \dots , s_{i-k+1})$. We will call the
$k$ the size of the window or also the \textit{smoothing parameter}. We can also simply change
the average function to the median to obtain the \textit{moving median}. For now, we will stick
to faster smoothing techniques.

The next difference that was visible from the comparison of real signal level string
and the simulated signal level string is that the real signal is more continuous instead
of a simulated signal that jumps. Again, we can use the moving average. Instead of
the moving median, it has a nice advantage that it causes signal not to jump from
one level to another but rather move continuously.

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.5\textheight]{images/testSmooth}}
\caption[Hehe]{Simulated signal vs real signal, normalized}
\label{obr:testSmooth}
\end{figure}

In Fig. \ref{obr:testSmooth} we can see the part of the simulated and corresponding real squiggle.
Then, in the subsequent two graphs, we apply the moving average with a window length
of 5. We can see that this smoothed the simulated squiggle but also smoothed the noise
that we could observe in the events. With the median smoothing, the outcome is quite
similar but lacks the quality of smoothing the simulated signal.

\section{Identification of Reads Based on Shared k-mers}

Now we want to show how we will distinguish if the two squiggles are similar or not.
What we will do is that we take the real squiggle, the reference squiggle corresponding to it, and
some other real squiggle. We will then try to tell which squiggle is from the reference
and which is not based only on the level strings of the respective squiggles. We
emphasized the speed many times, so we will try to come up with a fast test.
What we will do is that we will split the individual level strings into overlapping k-mers.
When we use the term k-mer in the context of the level string we mean any $k$ subsequent
characters from this string. We will then find what is the overlap
between k-mers from the reference squiggle and the sample squiggles. From the number of the overlaps, we will try
to predict, which sample squiggle is from the reference and which is not. This is very
simple heuristics but we think that this method could work well and also enables us
to only query for the individual k-mers in some index which is something that can be done really fast.
Besides the windows count, k-mer length is another useful parameter. We can estimate
that there will be a lot of shared k-mers of length less than 10 even between two unrelated
squiggles. As we gradually increase the length of the k-mer, we expect that the number
of random hits will decrease. On the other hand, we cannot increase the length of k-mer
too much as there is an increasing probability that some random noise or other anomalies
in the real squiggle causes the failure of finding the k-mer in the index.

\section{Experimental evaluation}

Now we will want to test our method in how accurately it represents the squiggle
through the level string and how informative this level string is. We will
look at how the level string from the simulated reference squiggle compares to the
level string of the real squiggle corresponding to this reference and random real squiggle
from the sequencing of another organism. We will not evaluate the level strings
only based on shared k-mers as this metric can be misleading.

\subsection{Experimental data}

Our data come from two organisms, one is Saprochaete ingens and the other one is
Saprochaete fungicola. Both of these organisms are yeasts. We choose these
organisms as they are sequenced by bioinformatics department of
FMPH so we have all the data from the sequencing easily available.
We have available the reference sequences of both these organisms as well as the
individual squiggles. We base-called these reads using the Albacore basecaller.
This basecaller develobed by Oxford Nanopore Technologies, company that develops also the MinION sequencer.

To see if these two organism do not share some big similarities, we tried to align the reads from
Saprochaete fungicola to the reference sequence of Saprochaete ingens.

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.4\textheight]{images/align_stat}}
\caption[TODO]{TODO}
\label{obr:align_stat}
\end{figure}

For our experiment, we use only the squiggles from the Saprochaete fungicola if they
are successfully aligned into the reference using the Nadavca. We then create the
simulated reference signal from the reference part that Nadavca identified, pick
some random read from the sequencing of the Saprochaete ingens and run our analysis
and run this cycle many times over.

\subsection{ROC curve}

A receiver operating characteristic curve is a graphical illustration of how well
the binary classificator performs on the data for particular threshold. The binary
classifier system is a system that tries to predict the binary output from the inputs.
We can predict based on the number of hits, if the squiggle is from the
simulated reference squiggle or not. We can choose some threshold $t$ and say that
our classificator predict all the squiggles with the number of hits bigger or equal
than $t$ as from the reference squiggle. When working with binary predictor there
are two important rates \textit{true positive rate} TPR and \textit{false positive rate} FPR. 

TPR is a ratio of the correctly classified positive squiggles to the number of the all squiggles.

FPR is a ratio of the squiggles that we incorrectly classified as positive.

The ROC works by ploting the dependency of FPR on TPR for various threshold values $t$.
If the binary classificator was random generator the ROC curve would be roughly
linear. Very good classificator obtains the curve that is very close to the point
$FPR = 0, TPR = 1$. We can see the example of very good curve on Fig. \ref{obr:roc}.

\begin{figure}
\centerline{\includegraphics[width=0.7\textwidth, height=0.3\textheight]{images/roc}}
\caption[TODO]{TODO}
\label{obr:roc}
\end{figure}

\subsection{Level string alignment}

To see how two level strings compare to each other we will align them. The input
to the alignment algorithm are two strings $s_1$, $s_2$:
$s_1=a_1a_2\cdots a_n$, $s_2=b_1b_2\cdots b_m$. The alignment are strings
$s_3$, $s_4: s_3 = c_1c_2c_3\cdots c_k$, $s_4 = d_1d_2d_3\cdots d_k$ such that:

\begin{enumerate}
\item $s_3$ and $s_4$ was created from $s_1$, $s_2$ respectively by inserting dashes
\item $c_i \neq d_i$ then $c_i = - \lor d_i = -$
\end{enumerate}

Example of allignment of $s_1 = AAACTGC$ and $s_2 = AACGTC$ is:

\begin{center}
$s_3 = $AAAC\,-\,TGC\\
$s_4 = $AA\,-\,CGT\,-\,C
\end{center}

There are a lot of alignments between the two strings. Most of the time we
are interested in some particular alignment. For this purpose, we will create a
scoring system and we will try to find the maximal (minimal) alignment in this scoring
system. We can, for example, minimize the number of dashes. Using the alignment
defined this way we can see how two-level strings compare to each other and how similar they are.
Finding the best alignment is not trivial. We use dynamic programming for
solving this problem. Let $T[i][j]$ be the best alignment of string $s_{1_i} = a_1a_2\cdots a_i$
and $s_{2_j} = b_1b_2\cdots b_j$. We will for simplification say that $\forall i, j: T[i][0] = i, T[0][j] = j$.

\[
T[i][j] = \bigl.
  \begin{cases}
    0, & \forall i,j : i\leq 0 \lor j\leq 0 \\
    max(T[i-1][j-1] + 1, T[i-1][j], T[i][j-1]) & \text{only if} \, a_i = b_i \\ 
    max(T[i-1][j], T[i][j-1]) & \text{otherwise}
  \end{cases}
\]

\subsection{Results}

The first thing that we evaluate is the number of shared k-mers as we already
stated this will be our main metric.

The second metric we will be interested in is mutual alignment of the sample
level strings and the reference level string. We will align them using the scoring
scheme we already presented. The problem with the shared k-mer count is that we only look
for the shared k-mers but we do not evaluate the relative positions of matched pairs.
This means that we can easily count as the matching pair also some two k-mers that
do not correspond to the same signal. With a reasonable number of levels, this will
not happen often for a short read. The big advantage of the alignment of the strings
is that it tells us more accurately what is the overall similarity of the level strings.

In Fig. \ref{obr:res_2} we see the ROC curve that represents how the overall number
of hits in the squiggles from the reference compares to the number of hits in the
random squiggle.

We then looked at what is the ratio of hits in the reference level string between squiggle
from this reference against random squiggle. In the \ref{obr:res_3} we see the cumulative percentage
of test cases that had respective ration. If the number of hits of the positive squiggle
was zero, we marked this as a negative thing and use the ratio 1:2.

In Figure \ref{obr:res_1} we looked more closely at the properties of the alignment. We
have been interested in how often we can see the successive dashes called \textit{gaps}.
We learned we need to distinguish between the length of the particular gaps. So we split
their count according to their length to the number of gaps shorter than 6 and longer than 9.
In the Figure \ref{obr:res_1} we present our findings for positive(squiggle from the reference)
and negative(random squiggle) squiggles. We present the ratio of the number of the gaps divided
by the length of the level string of the respective squiggles. For better visualization,
we show the gaps per 100 level string characters for gaps shorter than 6 and gaps
per 1000 level string characters for longer gaps. We can see that the number of gaps
shorter than six favors a lower number of levels and gradually increases with the number
of levels. The number of longer gaps behaves in the completely opposite way. 

The smoothing has a great impact on the resulst as we can see in Figure \ref{obr:res_2_nonorm}
and \ref{obr:res_3_nonorm}.

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.4\textheight]{images/res_2}}
\caption[TODO]{ROC curve of the hits}
\label{obr:res_2}
\end{figure}

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.4\textheight]{images/res_2_nonorm}}
\caption[TODO]{ROC curve of the hits without smoothing}
\label{obr:res_2_nonorm}
\end{figure}

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.4\textheight]{images/res_3}}
\caption[TODO]{Cummulative distribution of hit ratios}
\label{obr:res_3}
\end{figure}

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.4\textheight]{images/res_3_nonorm}}
\caption[TODO]{Cummulative distribution of hit ratios without smoothing}
\label{obr:res_3_nonorm}
\end{figure}

\begin{figure}
\centerline{\includegraphics[width=0.7\textwidth, height=0.4\textheight]{images/res_1}}
\caption[TODO]{TODO}
\label{obr:res_1}
\end{figure}
