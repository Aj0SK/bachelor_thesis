\chapter{Squiggle Discretization and Similarity Between Squiggles}

\label{kap:proposedMethod}

In this chapter, we will present our proposed method that will allow us to work
more easily with the squiggles.

\section{Squiggles as Sequencing of Discrete Observations}

When we obtain the simulated squiggle from the reference DNA, we want to be able
to decide during the process of sequencing if the squiggle currently passing
through the pore is from this reference squiggle. This comes down to finding if the
current squiggle is present somewhere in the reference squiggle. If both of the squiggles
are short, it is not that hard even for human eye to say, that two signals are from
roughly the same DNA sequence. However, we need to do this fast and on big number
of very long signals.

The idea of our solution is to discretize the squiggle simulated from the
reference sequence. We want to come with some better representation of the
squiggles that represents them well and also provides some advantages such as
easy searching in this representation. In our current setup, we are
not very limited by the preprocessing time but we need to decide very fast once
we are sequencing the DNA. This puts some speed limitations on our discretizing
process during the processing of the DNA. What we will do is that we will
represent the squiggle as a string of characters. We split the squiggle vertically into several
windows in such a manner that everything between some minimal and maximal
value is in some window. These windows are of constant length and do not
overlap. More formally, let $a_i$ be the readout at the time $i$, $m$ the number of
vertical windows. Now, we have some squiggle $s$ of length $n$, $s=a_1a_2a_3\cdots a_n$.
Besides this, we have some values $min_a$, $max_a$ that $\forall a_i: min_a \leq a_i < max_a$.
We say that the readout $a_i$ is in $j$-th window if it holds that:

\begin{center}
$min_a + j\cdot \frac{max_a-min_a}{m} \leq a_i < min_a + (j+1)\cdot \frac{max_a-min_a}{m}$
\end{center}

If the readouts $a_0, a_1, \cdots, a_n$ are in the windows $w_0, w_1, \cdots ,w_n$
respectively, we call $ls$ such that $ls=w_1w_2\cdots w_n$ the \textit{level string} of the
squiggle $s$. After this, we will contract subsequent occurrences of the same level.
So level string "aabccaa" becomes "abca". An example of the transformation of the squiggle
to the level string for $w=6$ is on \ref{obr:levelsCreation}.

\begin{figure}
\centerline{\includegraphics[width=0.8\textwidth, height=0.4\textheight]{images/levelsCreation}}
\caption[TODO]{Simulated signal vs real signal, normalized}
\label{obr:levelsCreation}
\end{figure}

This method has several good properties that we use. The first and obvious
property is that the same squiggle has the same level string each time for the
unchanged $w$. Besides this, small changes and oscillations in the squiggle will
eventually stay at the same level most of the time. We mentioned that the signal
consists of some events that are represented by a longer signal that is around the same level.
With this method, we hope that one event remains in the one window. Subsequent
contraction of the level string should cause that one event is in most cases represented by
one level.

Another good factor is that with the change of the parameter $w$ we can change how specific
and informative our method is. With the $w=2$ we can not say a lot about the two signals
that have level string equal. With bigger $w$ we can miss the two squiggles from
the same DNA sequence if there is a little noise present.

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.3\textheight]{images/levelDiff}}
\caption[TODO]{TODO}
\label{obr:levelDiff}
\end{figure}

We now look at the two scenarios when the number of levels is small and high.
We can see in \ref{obr:levelDiff} that for the small number of levels, small noise can cause signal to cross into another level. Even if the signal crossed the level border slightly, it creates the level
string equal to the signal that properly cross the border and remained in the level
most probably because of the real event. With high number of levels, like we see in \ref{obr:levelDiff} one event is less likely to remain in one window. It is caused mainly by the noise that can change very easily and this causes that
two squiggles from the same DNA sequence to not have the same level string.

\section{Simulating Squiggles from Reference}

We already stated that we need to obtain some reference squiggle that we
can sample and use to later split squiggles between that we are interested in and not
interested in. For this purpose, we need to take the reference in the form of a DNA sequence
and turn it into a signal. This simulation of the signal is based on the 6-mer kmer model.
For every 6-mer in our reference DNA, we will generate signal equal to the mean
of the gaussian distribution for that particular 6-mer.

This simulation does not take into account that the signal from one nucleotide is
measured several times. We already estimated that single nucleotide is on average
measured about 10 times so we will duplicate every entry in this simulated signal
10 times. We want to see how this signal compares to real signal so to put these
two into perspective we normalize this signal by subtracting mean and removing
standard deviation \ref{obr:simVsReal}.

\begin{figure}
\centerline{\includegraphics[width=0.7\textwidth, height=0.3\textheight]{images/simulateRef}}
\caption[Hehe]{Simulated signal vs real signal, normalized}
\label{obr:simVsReal}
\end{figure}

Now we have a simulated reference signal. On \ref{obr:simVsReal} we can see that the simulated and real
signal are not identical. This poses problems as we want to have these signals as
similar as possible. The first thing that we want to consider is normalization. There
are two possible approaches, local and global normalization. We will try both these
approaches. One of the most wide-spread ways of doing this is to subtract mean and dividing
signal by standard deviation. The other possible solution is subtracting median value
as the frequent outliers can deform the mean.

Another visible problem can be seen when we compare events in simulated and real squiggle
The events in the simulated signal are perfectly straight. In the real signal we can see
the phenomenon called \textit{drift}. This is fact that real event tends to slide
up or down throughout the time. The another difference is that the real squiggle
is sometimes contracted in some places. This is caused by the fact that the DNA
molecule is not moving through the pore at a constant speed.

As there are differences between simulated and real signal, there are two possible
ideas on how to overcome these differences. One is to make the simulated signal more like
the real signal. The first thing that we could do would be adding some Gaussian noise
that creates a more noisy signal. There are also some more advanced simulators of
signal such as DeepSimulator\cite{deepsimulator}. We want to go the other way and make the real signal
less noisy so we will now address the most important differences between simulated and real signal.

\subsection{Oscillations}

We already saw in \ref{obr:simVsReal} that one of the biggest differences between simulated and
real signal is the noise which can be seen as small oscillations of the signal. This is
one of the reasons that we use windows - so small oscillations within the window
are dealt with. We can also pretty easily adapt the number of windows.
However, when our method is used without any modifications it
produces much longer level string for real signal than for simulated signal.
The problem arises when the oscillations are located on the borders of the windows.
This is something that unfortunately happens too often.
There are several possibilities to deal with this behavior not affecting speed too
much. We tried several smoothing techniques to reduce noise. Moving average is the
smoothing technique that for every entry $s_i$ in some signal $s$ count its new value
$snew_i$ as $snew_i = avg(s_{i}, s_{i-1}, s_{i-2}, \dots , s_{i-k+1})$. We wil call the
$k$ the size of the window or also smoothing parameter. We can also simply change
the average function to median to obtain moving median. For now, we will stick
to faster solutions and choose one of the simpler techniques.

\subsection{Signal continuity}

The next difference that was visible from the comparison of real signal level string
and the simulated signal level string is that the real signal is more continuous instead
of a simulated signal that jumps. Again, we can use the moving average. Instead of
the moving median, it has a nice advantage that it causes signal not to jump from
one level to another but rather move continuously.

\begin{figure}
\centerline{\includegraphics[width=1.0\textwidth, height=0.5\textheight]{images/testSmooth}}
\caption[Hehe]{Simulated signal vs real signal, normalized}
\label{obr:testSmooth}
\end{figure}

In \ref{obr:testSmooth} we can see the part of simulated and corresponding real squiggle.
Then, in the subsequent two graphs, we apply the moving average with the window len
of 5. We can see that this smoothed the simulated signal but also smoothed the noise
that we could observed in the events. With the median smoothing the outcome is quite
similar but lacks in the quality of smoothing the simulated signal.

\section{Identification of Reads Based on Shared k-mers}

Now we will want to test our method of representation. What we will do is that we
take the read, reference corresponding to it and a some other read. We will then
try to tell which read is from the reference and which is not based only on the
level strings of the respective squiggles. We emphasized the speed many times, so
we will try to come up with the fast test. What we will do is that we will split the
individual level strings into overlapping k-mers. We will then find what is the overlap
between reference and the sample squiggles. From the number of the overlaps, we will try
to estimate, which sample squiggle is from the reference and which is not. This is very
simple heuristics but we think that this method could work well and also enables us
to only query for the indexed k-mer which is something that can be done really fast.
Beside the windows count this is another useful parametrizable metrics. We can estimate
that there will be a lot of shared kmers of len less than 10 even between two unrelated
squiggles. As we gradually increase the len of the kmer, we expect that the number
of random hits will decrease. On the other hand, we cannot increase the length of kmer
a lot because there is increasing probability that some random level causes the
whole hit to fail.

\section{Experimental evaluation}

We will now look at how the simulated reference signal compares to the raw read
corresponding to this reference and random read from the other sequencing. We will
not evaluate the data only based on shared k-mers as this metrics can be misleading.

\subsection{Data preparation}

For this experiments we will use the data that we discribe more closely in \ref{kap:apendA}
Hovewer, we will use the squiggles from the Saprochaete fungicola only if their signal
is successfully aligned into the reference using the Nadavca. We then create the
simulated reference signal from the reference part that Nadavca identified, pick
some random read from the sequencing of the Saprochaete ingens and run our analysis.

\subsection{Level string alignment}

To see how the reference level string and read level string compare to each other
we will align them. The input to the alignment algorithm are two strings $s_1$, $s_2$:
$s_1=a_1a_2\cdots a_n$, $s_2=b_1b_2\cdots b_m$. The alignment are strings
$s_3$, $s_4$: $s_3 = c_1c_2c_3\cdots c_k$, $s_4 = d_1d_2d_3\cdots d_k$
such that:

\begin{enumerate}
\item $s_3$ and $s_4$ was created from $s_1$, $s_2$ respectively by inserting dashes
\item $c_i \neq d_i$ then $c_i = - \lor d_i = -$
\end{enumerate}

Example of allignment of $s_1 = AAACTGC$ and $s_2 = AACGTC$ is:

\begin{center}
$s_3 = $AAAC\,-\,TGC\\
$s_4 = $AA\,-\,CGT\,-\,C
\end{center}

There are a lot of alignments of the two particular strings. Most of the time we
are interested in some particular alignment. For this purpose, we will create a
scoring system and we will try to find the maximum/minimum alignment in this scoring
system. We can, for example, minimize the number of dashes.

Using the alignment defined this way we can see how two-level strings compare to
each other and how similar they are.

Finding the best alignment is not trivial. We use a dynamic programming for
solving this problem. Let $T[i][j]$ be the best allignment of string $s_{1_i} = a_1a_2\cdots a_i$
and $s_{2_j} = b_1b_2\cdots b_j$. We will for simplification say that $\forall i, j: T[i][0] = i, T[0][j] = j$.

\[
T[i][j] = \bigl.
  \begin{cases}
    0, & \forall i,j : i\leq 0 \lor j\leq 0 \\
    max(T[i-1][j-1] + 1, T[i-1][j], T[i][j-1]) & \text{only if} \, a_i = b_i \\ 
    max(T[i-1][j], T[i][j-1]) & \text{otherwise}
  \end{cases}
\]

\subsection{Results}

The first thing that we evaluated is the number of shared k-mers as we already
stated this will be our first metric.

The second metrics we will be interested in is mutual alignment of the sample
level strings and the reference level string. We will align them using the scoring
scheme we already presented. The problem with the shared kmers is that we only look
for the shared kmers but we do not evaluate the relative positions of matched pairs.
This means that we can easily count as the matching pair also some two kmers that
do not correspond to the same signal. With the reasonable number of levels this will
not happen often for a short read. The big advantage of the allignment of the strings
is that it tells us more accurately what is the overall similarity of the level strings.

For the higher number of levels it is common to see the alignment equally
long between the both reads. This is caused by the fact that despite our eforts there
is too big difference between real and simulated signal so it is pretty common for
the alignment to miss some level. What is more obvious is that the common thing in
the
